{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "#import sys\n",
    "#sys.path.insert(0,'..')\n",
    "\n",
    "import os\n",
    "\n",
    "import backtrader as bt\n",
    "import backtrader.indicators as btind\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from scipy import stats\n",
    "\n",
    "from gym import spaces\n",
    "\n",
    "from btgym import BTgymEnv, BTgymStrategy, BTgymDataset\n",
    "\n",
    "from launcher import Launcher\n",
    "from model import LSTMPolicy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.rnn as rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleLSTM(LSTMPolicy):\n",
    "    def __init__(self, ob_space, ac_space):\n",
    "        \n",
    "\n",
    "        self.diagnostic = dict()\n",
    "\n",
    "        self.x = x = tf.placeholder(tf.float32, [None] + list(ob_space))\n",
    "\n",
    "        self.diagnostic['input_shape'] = self.x.shape\n",
    "        \n",
    "        #print('self.diagnostic0:', self.diagnostic)\n",
    "\n",
    "        # introduce a \"fake\" batch dimension of 1 after flatten so that we can do LSTM over time dim\n",
    "        x = tf.expand_dims(self.flatten(x), [0])\n",
    "\n",
    "        self.diagnostic['flatten_shape'] = x.shape\n",
    "        \n",
    "        #print('self.diagnostic1:', self.diagnostic)\n",
    "\n",
    "        size = 256\n",
    "        \n",
    "        #num_layers = 2\n",
    "\n",
    "        lstm = rnn.BasicLSTMCell(size, state_is_tuple=True)\n",
    "\n",
    "        self.state_size = lstm.state_size\n",
    "        \n",
    "        step_size = tf.shape(self.x)[:1]\n",
    "\n",
    "        self.diagnostic['step_size'] = step_size\n",
    "        \n",
    "        #print('self.diagnostic2:', self.diagnostic)\n",
    "\n",
    "        c_init = np.zeros((1, lstm.state_size.c), np.float32)\n",
    "        h_init = np.zeros((1, lstm.state_size.h), np.float32)\n",
    "        self.state_init = [c_init, h_init]\n",
    "        c_in = tf.placeholder(tf.float32, [1, lstm.state_size.c])\n",
    "        h_in = tf.placeholder(tf.float32, [1, lstm.state_size.h])\n",
    "        self.state_in = [c_in, h_in]\n",
    "\n",
    "        state_in = rnn.LSTMStateTuple(c_in, h_in)\n",
    "\n",
    "        lstm_outputs, lstm_state = tf.nn.dynamic_rnn(\n",
    "            lstm, x, initial_state=state_in, sequence_length=step_size,\n",
    "            time_major=False)\n",
    "\n",
    "        lstm_c, lstm_h = lstm_state\n",
    "        x = tf.reshape(lstm_outputs, [-1, size])\n",
    "        self.logits = self.linear(x, ac_space, \"action\", self.normalized_columns_initializer(0.01))\n",
    "        self.vf = tf.reshape(self.linear(x, 1, \"value\", self.normalized_columns_initializer(1.0)), [-1])\n",
    "        self.state_out = [lstm_c[:1, :], lstm_h[:1, :]]\n",
    "        self.sample = self.categorical_sample(self.logits, ac_space)[0, :]\n",
    "        self.var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, tf.get_variable_scope().name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:09,899] ./tmp/a3c_testing_6 created.\n"
     ]
    }
   ],
   "source": [
    "class MyStrategy(BTgymStrategy):\n",
    "    \"\"\"\n",
    "    Example subclass of BT server inner computation startegy.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyStrategy,self).__init__(**kwargs)\n",
    "        \n",
    "        self.current_value_embeded = np.ones(self.p.state_shape['raw_state'].shape[0]) * \\\n",
    "            self.p.target_call / (self.p.target_call + self.p.drawdown_call )\n",
    "\n",
    "        self.order_penalty = 2\n",
    "        self.trade_just_closed = False\n",
    "        self.trade_result = None\n",
    "        \n",
    "    def notify_trade(self, trade):\n",
    "        #if trade.justopened:\n",
    "            #print('trade {} just opened'.format(trade.ref))\n",
    "            \n",
    "        if trade.isclosed:\n",
    "            #print('trade {} closed, pnl_comm: {}'.format(trade.ref, trade.pnlcomm))\n",
    "            # Set trade flag and result:\n",
    "            self.trade_just_closed = True\n",
    "            self.trade_result = trade.pnlcomm\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "        \n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Computes featurized RL-ready environment observation state\n",
    "        by applying continious wavelet transform to time-embedded vector\n",
    "        of close-price gradients.\n",
    "        \"\"\"\n",
    "        # Use close price:\n",
    "        channel = 3\n",
    "        \n",
    "        X = self.raw_state[:, channel]\n",
    "        \n",
    "        # Prepare parameters:\n",
    "        Tau = 2\n",
    "        max_cwt_scale = self.p.state_shape['model_input'].shape[1] # - 1\n",
    "        cwt_width = np.linspace(Tau, max_cwt_scale + Tau - 1, max_cwt_scale) # scale of wavelet transdorm [n]\n",
    "    \n",
    "        T = 1e4\n",
    "        \n",
    "        # Get vector of gradients of last [n] prices:\n",
    "        X = np.gradient(X, axis=0) * T\n",
    "        \n",
    "        # Compute continious wavelet transform using Ricker wavelet, get [n,m,1]-dim. matrix:\n",
    "        X = signal.cwt(X, signal.ricker, cwt_width).T + 1\n",
    "\n",
    "        # Local min-max norm:\n",
    "        #X = (X - X.min()) / (X.max() - X.min())\n",
    "        #print('X:', X.shape)\n",
    "        #print('self.current_value_embeded:', self.current_value_embeded.shape)\n",
    "        \n",
    "        #self.state['model_input'] = np.concatenate([X, self.current_value_embeded[:, None] ], axis=-1)\n",
    "        \n",
    "        self.state['model_input'] = X\n",
    "        \n",
    "        #print('model_input:', self.state['model_input'].shape)\n",
    "        \n",
    "        # Squash values in [0,1]:\n",
    "        #self.state['model_input'] = self.sigmoid(self.state['model_input'])\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    \n",
    "    def get_reward(self):\n",
    "        \"\"\"\n",
    "        Defines reward as [0,1]-bounded function of last closed trade result.\n",
    "        \"\"\"\n",
    "        #r = 0\n",
    "        \n",
    "        r = (self.broker.get_value() / self.env.broker.startingcash - 1) * 10\n",
    "        \n",
    "        # Result\n",
    "        if self.trade_just_closed:\n",
    "            r += self.trade_result\n",
    "            self.trade_just_closed = False\n",
    "            #print('R-trade:', r)\n",
    "            \n",
    "        # Penalty for failed order:\n",
    "        if self.order_failed:\n",
    "            #print('Failed order!')\n",
    "            r -= self.order_penalty\n",
    "            self.order_failed = False\n",
    "            #print('R-failed:', r)\n",
    "            \n",
    "        #print('reward_', r)\n",
    "        \n",
    "        return r / 10\n",
    "    \n",
    "    def next(self):\n",
    "        \"\"\"\n",
    "        Extension of default implementation.\n",
    "        Defines one step environment routine for server 'Episode mode';\n",
    "        At least, it should handle order execution logic according to action received.\n",
    "        \"\"\"\n",
    "        # Normalized time-embedded vector of broker values:\n",
    "        self.current_value_embeded = np.roll(self.current_value_embeded, -1)\n",
    "        \n",
    "        self.current_value_embeded[-1] =\\\n",
    "            (self.broker.get_value() / self.env.broker.startingcash - 1 + self.p.drawdown_call / 100) / \\\n",
    "            (self.p.target_call + self.p.drawdown_call) * 100\n",
    "        \n",
    "        # Simple action-to-order logic:\n",
    "        if self.action == 'hold' or self.order:\n",
    "            pass\n",
    "        elif self.action == 'buy':\n",
    "            self.order = self.buy()\n",
    "            self.broker_message = 'New BUY created; ' + self.broker_message\n",
    "        elif self.action == 'sell':\n",
    "            self.order = self.sell()\n",
    "            self.broker_message = 'New SELL created; ' + self.broker_message\n",
    "        elif self.action == 'close':\n",
    "            self.order = self.close()\n",
    "            self.broker_message = 'New CLOSE created; ' + self.broker_message\n",
    "            \n",
    "# Set backtesting engine parameters:\n",
    "time_embed_dim = 30\n",
    "state_shape = {\n",
    "    'raw_state': spaces.Box(low=-1, high=1, shape=(time_embed_dim, 4)),\n",
    "    'model_input': spaces.Box(low=-10, high=10, shape=(time_embed_dim, 15))\n",
    "}\n",
    "\n",
    "MyCerebro = bt.Cerebro()\n",
    "\n",
    "MyCerebro.addstrategy(\n",
    "    MyStrategy,\n",
    "    state_shape=state_shape,\n",
    "    portfolio_actions=('hold', 'buy', 'sell'),\n",
    "    drawdown_call=5, # in percent of initial cash\n",
    "    target_call=20,\n",
    "    skip_frame=8,\n",
    ")\n",
    "\n",
    "# Set leveraged account:\n",
    "MyCerebro.broker.setcash(2000)\n",
    "MyCerebro.broker.setcommission(commission=0.0001, leverage=10.0)\n",
    "MyCerebro.broker.set_shortcash(False)\n",
    "MyCerebro.addsizer(bt.sizers.SizerFix, stake=10000,)\n",
    "\n",
    "\n",
    "MyCerebro.addanalyzer(bt.analyzers.DrawDown)\n",
    "\n",
    "# Provide data (seven years of 1 minute bars):\n",
    "filenames = [\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2010.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2011.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2012.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2013.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2014.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2015.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2016.csv',\n",
    "]\n",
    "\n",
    "MyDataset = BTgymDataset(\n",
    "    #filename=filenames,\n",
    "    filename='../data/test_sine_1min_period256_delta0002.csv',\n",
    "    start_weekdays=[0, 1, 2, 3, 4],\n",
    "    episode_len_days=0,\n",
    "    episode_len_hours=23,\n",
    "    episode_len_minutes=0,\n",
    "    start_00=False,\n",
    "    time_gap_hours=6,\n",
    ")\n",
    "env_config = dict(\n",
    "    dataset=MyDataset,\n",
    "    engine=MyCerebro,\n",
    "    render_modes=['episode', 'human', 'model_input'],\n",
    "    render_state_as_image=False,\n",
    "    render_ylabel='AVG,VAL Gradients',\n",
    "    render_size_episode=(12,8),\n",
    "    render_size_human=(8, 3.5),\n",
    "    render_size_state=(10, 5),\n",
    "    render_dpi=75,\n",
    "    port=5000,\n",
    "    data_port=4999,\n",
    "    connect_timeout=60,\n",
    "    verbose=0,\n",
    ")\n",
    "cluster_config = dict(\n",
    "    host='127.0.0.1',\n",
    "    port=12222,\n",
    "    num_workers=8,\n",
    "    num_ps=1,\n",
    "    log_dir='./tmp/a3c_testing_6',\n",
    ")\n",
    "launcher = Launcher(\n",
    "    cluster_config=cluster_config,\n",
    "    env_class=BTgymEnv,\n",
    "    env_config=env_config,\n",
    "    model_class=SimpleLSTM,\n",
    "    rollout_length=20,\n",
    "    test_mode=False,\n",
    "    train_steps=1000000000,\n",
    "    model_summary_freq=20,\n",
    "    episode_summary_freq=1,\n",
    "    env_render_freq=20,\n",
    "    verbose=1\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:16,223] Press `Ctrl-C` to stop training and close launcher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press `Ctrl-C` to stop training and close launcher.\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "LSTM init started\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "LSTM init started\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "LSTM init started\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "LSTM init started\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "LSTM init started\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "LSTM init started\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(15)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(450)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "INFO:tensorflow:Starting standard services.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:18,948] Starting standard services.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_6/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:19,012] Saving checkpoint to path ./tmp/a3c_testing_6/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:19,034] Starting queue runners.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:19,057] global/global_step/sec: 0\n",
      "[2017-08-25 19:10:19,165] worker_0: starting training at step: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:22,507] Starting queue runners.\n",
      "[2017-08-25 19:10:22,539] worker_2: starting training at step: 160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:22,701] Starting queue runners.\n",
      "[2017-08-25 19:10:22,782] worker_7: starting training at step: 160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:22,857] Starting queue runners.\n",
      "[2017-08-25 19:10:22,897] worker_3: starting training at step: 160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:22,934] Starting queue runners.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:22,999] worker_4: starting training at step: 160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:23,019] Starting queue runners.\n",
      "[2017-08-25 19:10:23,008] Starting queue runners.\n",
      "[2017-08-25 19:10:23,067] worker_1: starting training at step: 160\n",
      "[2017-08-25 19:10:23,066] worker_5: starting training at step: 160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:10:23,265] Starting queue runners.\n",
      "[2017-08-25 19:10:23,301] worker_6: starting training at step: 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 305.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:12:19,037] global/global_step/sec: 305.079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 231.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:14:19,061] global/global_step/sec: 231.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_6/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:15:19,015] Saving checkpoint to path ./tmp/a3c_testing_6/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 306.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:16:19,040] global/global_step/sec: 306.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 322.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:18:19,042] global/global_step/sec: 322.402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_6/train/model.ckpt\n",
      "INFO:tensorflow:global/global_step/sec: 326.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:20:19,002] Saving checkpoint to path ./tmp/a3c_testing_6/train/model.ckpt\n",
      "[2017-08-25 19:20:19,040] global/global_step/sec: 326.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 325.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:22:19,040] global/global_step/sec: 325.032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 299.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:24:19,041] global/global_step/sec: 299.232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_6/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:25:19,004] Saving checkpoint to path ./tmp/a3c_testing_6/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 306.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:26:19,040] global/global_step/sec: 306.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 319.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:28:19,045] global/global_step/sec: 319.387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_6/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-25 19:30:19,000] Saving checkpoint to path ./tmp/a3c_testing_6/train/model.ckpt\n",
      "Process DrawCerebro-179:2:155:\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process BTgymServer-186:1:\n",
      "Process BTgymServer-182:1:\n",
      "Process BTgymServer-180:1:\n",
      "Process BTgymDataFeedServer-179:1:\n",
      "Process BTgymServer-181:1:\n",
      "Process BTgymServer-185:1:\n",
      "Process BTgymServer-184:1:\n",
      "[2017-08-25 19:31:38,491] worker_1 has joined.\n",
      "Process BTgymServer-183:1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 433, in run\n",
      "    gc.collect()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/dataserver.py\", line 100, in run\n",
      "    service_input = socket.recv_pyobj()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 413, in run\n",
      "    episode = cerebro.run(stdstats=True, preload=False, oldbuysell=True)[0]\n",
      "[2017-08-25 19:31:39,550] worker_2 has joined.\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/zmq/sugar/socket.py\", line 491, in recv_pyobj\n",
      "    msg = self.recv(flags)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1073, in run\n",
      "    runstrat = self.runstrategies(iterstrat)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1235, in runstrategies\n",
      "    self._runnext(runstrats)\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 413, in run\n",
      "    episode = cerebro.run(stdstats=True, preload=False, oldbuysell=True)[0]\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 693, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "[2017-08-25 19:31:39,720] worker_3 has joined.\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1557, in _runnext\n",
      "    self._brokernotify()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 413, in run\n",
      "    episode = cerebro.run(stdstats=True, preload=False, oldbuysell=True)[0]\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1073, in run\n",
      "    runstrat = self.runstrategies(iterstrat)\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 413, in run\n",
      "    episode = cerebro.run(stdstats=True, preload=False, oldbuysell=True)[0]\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1235, in runstrategies\n",
      "    self._runnext(runstrats)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1073, in run\n",
      "    runstrat = self.runstrategies(iterstrat)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1297, in _brokernotify\n",
      "    self._broker.next()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1073, in run\n",
      "    runstrat = self.runstrategies(iterstrat)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1235, in runstrategies\n",
      "    self._runnext(runstrats)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1564, in _runnext\n",
      "    strat._next()\n",
      "[2017-08-25 19:31:39,783] worker_4 has joined.\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1235, in runstrategies\n",
      "    self._runnext(runstrats)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/brokers/bbroker.py\", line 1032, in next\n",
      "    def next(self):\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 727, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/strategy.py\", line 327, in _next\n",
      "    self._next_analyzers(minperstatus)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1557, in _runnext\n",
      "    self._brokernotify()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1564, in _runnext\n",
      "    strat._next()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "[2017-08-25 19:31:39,798] worker_5 has joined.\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 145, in zmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/strategy.py\", line 328, in _next\n",
      "    self._next_observers(minperstatus)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/strategy.py\", line 361, in _next_analyzers\n",
      "    analyzer._next()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1297, in _brokernotify\n",
      "    self._broker.next()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 413, in run\n",
      "    episode = cerebro.run(stdstats=True, preload=False, oldbuysell=True)[0]\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/analyzer.py\", line 188, in _next\n",
      "    self.next()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/brokers/bbroker.py\", line 1079, in next\n",
      "    if pos:\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/strategy.py\", line 356, in _next_observers\n",
      "    observer._next()\n",
      "[2017-08-25 19:31:39,831] worker_6 has joined.\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1073, in run\n",
      "    runstrat = self.runstrategies(iterstrat)\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 413, in run\n",
      "    episode = cerebro.run(stdstats=True, preload=False, oldbuysell=True)[0]\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/lineiterator.py\", line 255, in _next\n",
      "    clock_len = self._clk_update()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 145, in next\n",
      "    self.socket.send_pyobj((state, reward, is_done, self.info_list))\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1235, in runstrategies\n",
      "    self._runnext(runstrats)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/position.py\", line 116, in __bool__\n",
      "    def __bool__(self):\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1073, in run\n",
      "    runstrat = self.runstrategies(iterstrat)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1564, in _runnext\n",
      "    strat._next()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/lineiterator.py\", line 282, in _clk_update\n",
      "    clock_len = len(self._clock)\n",
      "[2017-08-25 19:31:39,833] worker_7 has joined.\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/zmq/sugar/socket.py\", line 476, in send_pyobj\n",
      "    return self.send(msg, flags)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1235, in runstrategies\n",
      "    self._runnext(runstrats)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/strategy.py\", line 324, in _next\n",
      "    super(Strategy, self)._next()\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 636, in zmq.backend.cython.socket.Socket.send (zmq/backend/cython/socket.c:7305)\n",
      "[2017-08-25 19:31:39,835] chief_worker_0 has joined.  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/lineseries.py\", line 463, in __len__\n",
      "    return len(self.lines)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1564, in _runnext\n",
      "    strat._next()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/lineseries.py\", line 220, in __len__\n",
      "    return len(self.lines[0])\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/lineiterator.py\", line 258, in _next\n",
      "    indicator._next()\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 683, in zmq.backend.cython.socket.Socket.send (zmq/backend/cython/socket.c:7048)\n",
      "\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/strategy.py\", line 327, in _next\n",
      "    self._next_analyzers(minperstatus)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 201, in zmq.backend.cython.socket._send_copy (zmq/backend/cython/socket.c:2920)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/lineiterator.py\", line 258, in _next\n",
      "    indicator._next()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/strategy.py\", line 361, in _next_analyzers\n",
      "    analyzer._next()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/lineiterator.py\", line 275, in _next\n",
      "    self.next()\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/analyzer.py\", line 188, in _next\n",
      "    self.next()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/indicators/basicops.py\", line 356, in next\n",
      "    math.fsum(self.data.get(size=self.p.period)) / self.p.period\n",
      "[2017-08-25 19:31:39,961] parameter_server_0 has joined.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 103, in next\n",
      "    state = self.strategy.get_state()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/linebuffer.py\", line 222, in __setitem__\n",
      "    self.array[self.idx + ago] = value\n",
      "  File \"<ipython-input-47-ef79c678dfbe>\", line 50, in get_state\n",
      "    X = signal.cwt(X, signal.ricker, cwt_width).T + 1\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/rendering/plotter.py\", line 73, in run\n",
      "    figfilename='_tmp_btgym_render.png',\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/scipy/signal/wavelets.py\", line 364, in cwt\n",
      "    mode='same')\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 941, in plot\n",
      "    tight=tight)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/scipy/signal/signaltools.py\", line 783, in convolve\n",
      "    method = choose_conv_method(volume, kernel, mode=mode)\n",
      "[2017-08-25 19:31:39,963] Launcher closed.\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/rendering/plotter.py\", line 46, in savefig\n",
      "    fig.canvas.draw()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\", line 464, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/scipy/signal/signaltools.py\", line 666, in choose_conv_method\n",
      "    if volume.dtype == fftconv_unsup or kernel.dtype == fftconv_unsup:\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/artist.py\", line 63, in draw_wrapper\n",
      "    draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/figure.py\", line 1135, in draw\n",
      "    self.tight_layout(renderer, **self._tight_parameters)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/figure.py\", line 1753, in tight_layout\n",
      "    rect=rect)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/tight_layout.py\", line 353, in get_tight_layout_figure\n",
      "    pad=pad, h_pad=h_pad, w_pad=w_pad)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/tight_layout.py\", line 129, in auto_adjust_subplotpars\n",
      "    tight_bbox_raw = union([ax.get_tightbbox(renderer) for ax in subplots\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/tight_layout.py\", line 130, in <listcomp>\n",
      "    if ax.get_visible()])\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axes/_base.py\", line 3827, in get_tightbbox\n",
      "    bb_yaxis = self.yaxis.get_tightbbox(renderer)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axis.py\", line 1095, in get_tightbbox\n",
      "    renderer)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axis.py\", line 1078, in _get_tick_bboxes\n",
      "    extent = tick.label1.get_window_extent(renderer)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/text.py\", line 970, in get_window_extent\n",
      "    bbox = bbox.translated(x, y)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/transforms.py\", line 699, in translated\n",
      "    return Bbox(self._points + (tx, ty))\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/transforms.py\", line 795, in __init__\n",
      "    self._minpos = np.array([np.inf, np.inf])\n",
      "KeyboardInterrupt\n",
      "[2017-08-25 19:32:44,016] BtgymServer: data_server unreachable with status: <receive_failed>.\n",
      "Process BTgymServer-179:2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 398, in run\n",
      "    raise ConnectionError(msg)\n",
      "ConnectionError: BtgymServer: data_server unreachable with status: <receive_failed>.\n"
     ]
    }
   ],
   "source": [
    "launcher.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(launcher.kwargs, '\\n\\n')\n",
    "print(launcher.env_config)\n",
    "print(launcher.cluster_config)\n",
    "print(launcher.cluster_spec)\n",
    "for config in launcher.workers_config_list:\n",
    "    print('============')\n",
    "    for k, v in config.items():\n",
    "        print('{}:\\n{}\\n'.format(k, v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func1(max_step):\n",
    "    step = 0\n",
    "    done = False\n",
    "    \n",
    "    def func2(max_step):\n",
    "        nonlocal step\n",
    "        nonlocal done\n",
    "        step +=1\n",
    "        if step == max_step:\n",
    "            step = 0\n",
    "            done = True\n",
    "        return step\n",
    "    \n",
    "    for i in range(20):\n",
    "        done = False\n",
    "        print(func2(max_step), step, done)\n",
    "        \n",
    "\n",
    "\n",
    "func1(7)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = dict()\n",
    "a.update({'b': 2, 'c':4})\n",
    "type(a) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
