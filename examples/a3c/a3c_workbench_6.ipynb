{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "#import sys\n",
    "#sys.path.insert(0,'..')\n",
    "\n",
    "import os\n",
    "\n",
    "import backtrader as bt\n",
    "import backtrader.indicators as btind\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from scipy import stats\n",
    "\n",
    "from gym import spaces\n",
    "\n",
    "from btgym import BTgymEnv, BTgymStrategy, BTgymDataset\n",
    "\n",
    "from launcher import Launcher\n",
    "from model import LSTMPolicy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.rnn as rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleLSTM(LSTMPolicy):\n",
    "    def __init__(self, ob_space, ac_space):\n",
    "        \n",
    "        print('LSTM init started')\n",
    "\n",
    "        self.diagnostic = dict()\n",
    "\n",
    "        self.x = x = tf.placeholder(tf.float32, [None] + list(ob_space))\n",
    "\n",
    "        self.diagnostic['input_shape'] = self.x.shape\n",
    "        \n",
    "        print('self.diagnostic0:', self.diagnostic)\n",
    "\n",
    "        # introduce a \"fake\" batch dimension of 1 after flatten so that we can do LSTM over time dim\n",
    "        x = tf.expand_dims(self.flatten(x), [0])\n",
    "\n",
    "        self.diagnostic['flatten_shape'] = x.shape\n",
    "        \n",
    "        print('self.diagnostic1:', self.diagnostic)\n",
    "\n",
    "        size = 256\n",
    "\n",
    "        lstm = rnn.BasicLSTMCell(size, state_is_tuple=True)\n",
    "\n",
    "        self.state_size = lstm.state_size\n",
    "        step_size = tf.shape(self.x)[:1]\n",
    "\n",
    "        self.diagnostic['step_size'] = step_size\n",
    "        \n",
    "        print('self.diagnostic2:', self.diagnostic)\n",
    "\n",
    "        c_init = np.zeros((1, lstm.state_size.c), np.float32)\n",
    "        h_init = np.zeros((1, lstm.state_size.h), np.float32)\n",
    "        self.state_init = [c_init, h_init]\n",
    "        c_in = tf.placeholder(tf.float32, [1, lstm.state_size.c])\n",
    "        h_in = tf.placeholder(tf.float32, [1, lstm.state_size.h])\n",
    "        self.state_in = [c_in, h_in]\n",
    "\n",
    "        state_in = rnn.LSTMStateTuple(c_in, h_in)\n",
    "\n",
    "        lstm_outputs, lstm_state = tf.nn.dynamic_rnn(\n",
    "            lstm, x, initial_state=state_in, sequence_length=step_size,\n",
    "            time_major=False)\n",
    "\n",
    "        lstm_c, lstm_h = lstm_state\n",
    "        x = tf.reshape(lstm_outputs, [-1, size])\n",
    "        self.logits = self.linear(x, ac_space, \"action\", self.normalized_columns_initializer(0.01))\n",
    "        self.vf = tf.reshape(self.linear(x, 1, \"value\", self.normalized_columns_initializer(1.0)), [-1])\n",
    "        self.state_out = [lstm_c[:1, :], lstm_h[:1, :]]\n",
    "        self.sample = self.categorical_sample(self.logits, ac_space)[0, :]\n",
    "        self.var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, tf.get_variable_scope().name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:06,025] Launcher ready.\n"
     ]
    }
   ],
   "source": [
    "class MyStrategy(BTgymStrategy):\n",
    "    \"\"\"\n",
    "    Example subclass of BT server inner computation startegy.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyStrategy,self).__init__(**kwargs)\n",
    "        \n",
    "        self.current_value_embeded = np.ones(self.p.state_shape['raw_state'].shape[0]) * \\\n",
    "            self.p.target_call / (self.p.target_call + self.p.drawdown_call )\n",
    "\n",
    "        self.order_penalty = 0.5\n",
    "        self.trade_just_closed = False\n",
    "        self.trade_result = None\n",
    "        \n",
    "    def notify_trade(self, trade):\n",
    "        #if trade.justopened:\n",
    "            #print('trade {} just opened'.format(trade.ref))\n",
    "            \n",
    "        if trade.isclosed:\n",
    "            #print('trade {} closed, pnl_comm: {}'.format(trade.ref, trade.pnlcomm))\n",
    "            # Set trade flag and result:\n",
    "            self.trade_just_closed = True\n",
    "            self.trade_result = trade.pnlcomm\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "        \n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Computes featurized RL-ready environment observation state\n",
    "        by applying continious wavelet transform to time-embedded vector\n",
    "        of close-price gradients.\n",
    "        \"\"\"\n",
    "        # Use close price:\n",
    "        channel = 3\n",
    "        \n",
    "        X = self.raw_state[:, channel]\n",
    "        \n",
    "        # Prepare parameters:\n",
    "        Tau = 2\n",
    "        max_cwt_scale = self.p.state_shape['model_input'].shape[1] - 1\n",
    "        cwt_width = np.linspace(Tau, max_cwt_scale + Tau - 1, max_cwt_scale) # scale of wavelet transdorm [n]\n",
    "    \n",
    "        T = 1# 000\n",
    "        \n",
    "        # Get vector of gradients of last [n] prices:\n",
    "        X = np.gradient(X, axis=0) * T\n",
    "        \n",
    "        # Compute continious wavelet transform using Ricker wavelet, get [n,m,1]-dim. matrix:\n",
    "        X = signal.cwt(X, signal.ricker, cwt_width).T\n",
    "\n",
    "        # Local min-max norm:\n",
    "        X = (X - X.min()) / (X.max() - X.min())\n",
    "        #print('X:', X.shape)\n",
    "        #print('self.current_value_embeded:', self.current_value_embeded.shape)\n",
    "        \n",
    "        self.state['model_input'] = np.concatenate([X, self.current_value_embeded[:, None] ], axis=-1)\n",
    "        \n",
    "        #print('model_input:', self.state['model_input'].shape)\n",
    "        \n",
    "        # Squash values in [0,1]:\n",
    "        #self.state['model_input'] = self.sigmoid(self.state['model_input'])\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    \n",
    "    def get_reward(self):\n",
    "        \"\"\"\n",
    "        Defines reward as [0,1]-bounded function of last closed trade result.\n",
    "        \"\"\"\n",
    "        r = 0\n",
    "        \n",
    "        # Result\n",
    "        if self.trade_just_closed:\n",
    "            r = self.trade_result\n",
    "            self.trade_just_closed = False\n",
    "            \n",
    "        # Penalty for failed order:\n",
    "        if self.order_failed:\n",
    "            #print('Failed order!')\n",
    "            r -= self.order_penalty\n",
    "            self.order_failed = False\n",
    "            \n",
    "        #print('reward_', r)\n",
    "        \n",
    "        return r / 20\n",
    "    \n",
    "    def next(self):\n",
    "        \"\"\"\n",
    "        Extension of default implementation.\n",
    "        Defines one step environment routine for server 'Episode mode';\n",
    "        At least, it should handle order execution logic according to action received.\n",
    "        \"\"\"\n",
    "        # Normalized time-embedded vector of broker values:\n",
    "        self.current_value_embeded = np.roll(self.current_value_embeded, -1)\n",
    "        \n",
    "        self.current_value_embeded[-1] =\\\n",
    "            (self.broker.get_value() / self.env.broker.startingcash - 1 + self.p.drawdown_call / 100) / \\\n",
    "            (self.p.target_call + self.p.drawdown_call) * 100\n",
    "        \n",
    "        # Simple action-to-order logic:\n",
    "        if self.action == 'hold' or self.order:\n",
    "            pass\n",
    "        elif self.action == 'buy':\n",
    "            self.order = self.buy()\n",
    "            self.broker_message = 'New BUY created; ' + self.broker_message\n",
    "        elif self.action == 'sell':\n",
    "            self.order = self.sell()\n",
    "            self.broker_message = 'New SELL created; ' + self.broker_message\n",
    "        elif self.action == 'close':\n",
    "            self.order = self.close()\n",
    "            self.broker_message = 'New CLOSE created; ' + self.broker_message\n",
    "            \n",
    "# Set backtesting engine parameters:\n",
    "time_embed_dim = 30\n",
    "state_shape = {\n",
    "    'raw_state': spaces.Box(low=-1, high=1, shape=(time_embed_dim, 4)),\n",
    "    'model_input': spaces.Box(low=-10, high=10, shape=(time_embed_dim, 16))\n",
    "}\n",
    "\n",
    "MyCerebro = bt.Cerebro()\n",
    "\n",
    "MyCerebro.addstrategy(\n",
    "    MyStrategy,\n",
    "    state_shape=state_shape,\n",
    "    portfolio_actions=('hold', 'buy', 'sell'),\n",
    "    drawdown_call=5, # in percent of initial cash\n",
    "    target_call=20,\n",
    "    skip_frame=10,\n",
    ")\n",
    "\n",
    "# Set leveraged account:\n",
    "MyCerebro.broker.setcash(2000)\n",
    "MyCerebro.broker.setcommission(commission=0.0001, leverage=10.0)\n",
    "MyCerebro.broker.set_shortcash(False)\n",
    "MyCerebro.addsizer(bt.sizers.SizerFix, stake=10000,)\n",
    "\n",
    "\n",
    "MyCerebro.addanalyzer(bt.analyzers.DrawDown)\n",
    "\n",
    "# Provide data (seven years of 1 minute bars):\n",
    "filenames = [\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2010.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2011.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2012.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2013.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2014.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2015.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2016.csv',\n",
    "]\n",
    "\n",
    "MyDataset = BTgymDataset(\n",
    "    filename=filenames,\n",
    "    #filename='../data/test_sine_1min_period256_delta0002.csv',\n",
    "    start_weekdays=[0, 1, 2, 3, 4],\n",
    "    episode_len_days=0,\n",
    "    episode_len_hours=23,\n",
    "    episode_len_minutes=0,\n",
    "    start_00=False,\n",
    "    time_gap_hours=6,\n",
    ")\n",
    "env_config = dict(\n",
    "    dataset=MyDataset,\n",
    "    engine=MyCerebro,\n",
    "    render_modes=['episode', 'human', 'model_input'],\n",
    "    render_state_as_image=False,\n",
    "    render_ylabel='AVG,VAL Gradients',\n",
    "    render_size_episode=(12,8),\n",
    "    render_size_human=(8, 3.5),\n",
    "    render_size_state=(10, 5),\n",
    "    render_dpi=75,\n",
    "    port=5000,\n",
    "    data_port=4999,\n",
    "    connect_timeout=60,\n",
    "    verbose=0,\n",
    ")\n",
    "cluster_config = dict(\n",
    "    host='127.0.0.1',\n",
    "    port=12222,\n",
    "    num_workers=8,\n",
    "    num_ps=1,\n",
    "    log_dir='./tmp/a3c_testing_2',\n",
    ")\n",
    "launcher = Launcher(\n",
    "    cluster_config=cluster_config,\n",
    "    env_class=BTgymEnv,\n",
    "    env_config=env_config,\n",
    "    model_class=SimpleLSTM,\n",
    "    rollout_length=20,\n",
    "    test_mode=False,\n",
    "    train_steps=1000000000,\n",
    "    model_summary_freq=20,\n",
    "    episode_summary_freq=1,\n",
    "    env_render_freq=20,\n",
    "    verbose=2\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:06,051] parameters_server started.\n",
      "[2017-08-24 22:26:06,056] worker_0 tf.server started.\n",
      "[2017-08-24 22:26:06,059] making environment.\n",
      "[2017-08-24 22:26:06,061] worker_0 is data_master: True\n",
      "[2017-08-24 22:26:11,065] worker_1 tf.server started.\n",
      "[2017-08-24 22:26:11,084] making environment.\n",
      "[2017-08-24 22:26:11,079] worker_2 tf.server started.\n",
      "[2017-08-24 22:26:11,092] worker_1 is data_master: False\n",
      "[2017-08-24 22:26:11,101] making environment.\n",
      "[2017-08-24 22:26:11,109] worker_2 is data_master: False\n",
      "[2017-08-24 22:26:11,140] Press `Ctrl-C` to stop training and close launcher.\n",
      "[2017-08-24 22:26:11,156] worker_3 tf.server started.\n",
      "[2017-08-24 22:26:11,167] worker_4 tf.server started.\n",
      "[2017-08-24 22:26:11,185] making environment.\n",
      "[2017-08-24 22:26:11,197] worker_3 is data_master: False\n",
      "[2017-08-24 22:26:11,198] making environment.\n",
      "[2017-08-24 22:26:11,206] worker_4 is data_master: False\n",
      "[2017-08-24 22:26:11,193] worker_5 tf.server started.\n",
      "[2017-08-24 22:26:11,244] making environment.\n",
      "[2017-08-24 22:26:11,254] worker_5 is data_master: False\n",
      "[2017-08-24 22:26:11,249] worker_6 tf.server started.\n",
      "[2017-08-24 22:26:11,255] worker_7 tf.server started.\n",
      "[2017-08-24 22:26:11,261] making environment.\n",
      "[2017-08-24 22:26:11,261] making environment.\n",
      "[2017-08-24 22:26:11,263] worker_6 is data_master: False\n",
      "[2017-08-24 22:26:11,266] worker_7 is data_master: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press `Ctrl-C` to stop training and close launcher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:13,474] worker_1:envronment ok.\n",
      "[2017-08-24 22:26:13,474] worker_2:envronment ok.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A3C_1 init started\n",
      "A3C_2 init started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:13,475] worker_0:envronment ok.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM init started\n",
      "A3C_0 init started\n",
      "LSTM init started\n",
      "LSTM init started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:13,492] worker_3:envronment ok.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A3C_3 init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:13,513] worker_4:envronment ok.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "A3C_4 init started\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "LSTM init started\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:13,540] worker_6:envronment ok.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "A3C_6 init started\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "LSTM init started\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:13,568] worker_7:envronment ok.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "A3C_7 init started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:13,587] worker_5:envronment ok.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "A3C_5 init started\n",
      "LSTM init started\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'global/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "LSTM init started\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "LSTM init started\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "LSTM init started\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "LSTM init started\n",
      "LSTM init started\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "self.diagnostic0: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "self.diagnostic1: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)])}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "self.diagnostic2: {'input_shape': TensorShape([Dimension(None), Dimension(30), Dimension(16)]), 'flatten_shape': TensorShape([Dimension(1), Dimension(None), Dimension(480)]), 'step_size': <tf.Tensor 'local/strided_slice:0' shape=(1,) dtype=int32>}\n",
      "A3C_6 train op defined\n",
      "A3C_3 train op defined\n",
      "A3C_5 train op defined\n",
      "A3C_0 train op defined\n",
      "A3C_1 train op defined\n",
      "A3C_7 train op defined\n",
      "A3C_2 train op defined\n",
      "A3C_4 train op defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:17,032] worker_6:trainer ok.\n",
      "[2017-08-24 22:26:17,045] worker_3:trainer ok.\n",
      "[2017-08-24 22:26:17,047] worker_5:trainer ok.\n",
      "[2017-08-24 22:26:17,058] worker_1:trainer ok.\n",
      "[2017-08-24 22:26:17,065] worker_0:trainer ok.\n",
      "[2017-08-24 22:26:17,110] worker_2:trainer ok.\n",
      "[2017-08-24 22:26:17,118] worker_7:trainer ok.\n",
      "[2017-08-24 22:26:17,185] worker_4:trainer ok.\n",
      "[2017-08-24 22:26:18,582] connecting to the parameter server... \n",
      "[2017-08-24 22:26:18,591] connecting to the parameter server... \n",
      "[2017-08-24 22:26:18,599] connecting to the parameter server... \n",
      "[2017-08-24 22:26:18,599] connecting to the parameter server... \n",
      "[2017-08-24 22:26:18,609] connecting to the parameter server... \n",
      "[2017-08-24 22:26:18,643] connecting to the parameter server... \n",
      "[2017-08-24 22:26:18,682] connecting to the parameter server... \n",
      "[2017-08-24 22:26:18,732] connecting to the parameter server... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global/rnn/basic_lstm_cell/kernel, global/rnn/basic_lstm_cell/bias, global/action/w, global/action/b, global/value/w, global/value/b, global/global_step, global/global_episode, beta1_power, beta2_power, global/rnn/basic_lstm_cell/kernel/Adam, global/rnn/basic_lstm_cell/kernel/Adam_1, global/rnn/basic_lstm_cell/bias/Adam, global/rnn/basic_lstm_cell/bias/Adam_1, global/action/w/Adam, global/action/w/Adam_1, global/action/b/Adam, global/action/b/Adam_1, global/value/w/Adam, global/value/w/Adam_1, global/value/b/Adam, global/value/b/Adam_1\n",
      "INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global/rnn/basic_lstm_cell/kernel, global/rnn/basic_lstm_cell/bias, global/action/w, global/action/b, global/value/w, global/value/b, global/global_step, global/global_episode, beta1_power, beta2_power, global/rnn/basic_lstm_cell/kernel/Adam, global/rnn/basic_lstm_cell/kernel/Adam_1, global/rnn/basic_lstm_cell/bias/Adam, global/rnn/basic_lstm_cell/bias/Adam_1, global/action/w/Adam, global/action/w/Adam_1, global/action/b/Adam, global/action/b/Adam_1, global/value/w/Adam, global/value/w/Adam_1, global/value/b/Adam, global/value/b/Adam_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:19,768] Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global/rnn/basic_lstm_cell/kernel, global/rnn/basic_lstm_cell/bias, global/action/w, global/action/b, global/value/w, global/value/b, global/global_step, global/global_episode, beta1_power, beta2_power, global/rnn/basic_lstm_cell/kernel/Adam, global/rnn/basic_lstm_cell/kernel/Adam_1, global/rnn/basic_lstm_cell/bias/Adam, global/rnn/basic_lstm_cell/bias/Adam_1, global/action/w/Adam, global/action/w/Adam_1, global/action/b/Adam, global/action/b/Adam_1, global/value/w/Adam, global/value/w/Adam_1, global/value/b/Adam, global/value/b/Adam_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global/rnn/basic_lstm_cell/kernel, global/rnn/basic_lstm_cell/bias, global/action/w, global/action/b, global/value/w, global/value/b, global/global_step, global/global_episode, beta1_power, beta2_power, global/rnn/basic_lstm_cell/kernel/Adam, global/rnn/basic_lstm_cell/kernel/Adam_1, global/rnn/basic_lstm_cell/bias/Adam, global/rnn/basic_lstm_cell/bias/Adam_1, global/action/w/Adam, global/action/w/Adam_1, global/action/b/Adam, global/action/b/Adam_1, global/value/w/Adam, global/value/w/Adam_1, global/value/b/Adam, global/value/b/Adam_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:19,783] Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global/rnn/basic_lstm_cell/kernel, global/rnn/basic_lstm_cell/bias, global/action/w, global/action/b, global/value/w, global/value/b, global/global_step, global/global_episode, beta1_power, beta2_power, global/rnn/basic_lstm_cell/kernel/Adam, global/rnn/basic_lstm_cell/kernel/Adam_1, global/rnn/basic_lstm_cell/bias/Adam, global/rnn/basic_lstm_cell/bias/Adam_1, global/action/w/Adam, global/action/w/Adam_1, global/action/b/Adam, global/action/b/Adam_1, global/value/w/Adam, global/value/w/Adam_1, global/value/b/Adam, global/value/b/Adam_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global/rnn/basic_lstm_cell/kernel, global/rnn/basic_lstm_cell/bias, global/action/w, global/action/b, global/value/w, global/value/b, global/global_step, global/global_episode, beta1_power, beta2_power, global/rnn/basic_lstm_cell/kernel/Adam, global/rnn/basic_lstm_cell/kernel/Adam_1, global/rnn/basic_lstm_cell/bias/Adam, global/rnn/basic_lstm_cell/bias/Adam_1, global/action/w/Adam, global/action/w/Adam_1, global/action/b/Adam, global/action/b/Adam_1, global/value/w/Adam, global/value/w/Adam_1, global/value/b/Adam, global/value/b/Adam_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:19,812] Initializing all parameters.\n",
      "[2017-08-24 22:26:19,799] Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global/rnn/basic_lstm_cell/kernel, global/rnn/basic_lstm_cell/bias, global/action/w, global/action/b, global/value/w, global/value/b, global/global_step, global/global_episode, beta1_power, beta2_power, global/rnn/basic_lstm_cell/kernel/Adam, global/rnn/basic_lstm_cell/kernel/Adam_1, global/rnn/basic_lstm_cell/bias/Adam, global/rnn/basic_lstm_cell/bias/Adam_1, global/action/w/Adam, global/action/w/Adam_1, global/action/b/Adam, global/action/b/Adam_1, global/value/w/Adam, global/value/w/Adam_1, global/value/b/Adam, global/value/b/Adam_1\n",
      "[2017-08-24 22:26:19,803] Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global/rnn/basic_lstm_cell/kernel, global/rnn/basic_lstm_cell/bias, global/action/w, global/action/b, global/value/w, global/value/b, global/global_step, global/global_episode, beta1_power, beta2_power, global/rnn/basic_lstm_cell/kernel/Adam, global/rnn/basic_lstm_cell/kernel/Adam_1, global/rnn/basic_lstm_cell/bias/Adam, global/rnn/basic_lstm_cell/bias/Adam_1, global/action/w/Adam, global/action/w/Adam_1, global/action/b/Adam, global/action/b/Adam_1, global/value/w/Adam, global/value/w/Adam_1, global/value/b/Adam, global/value/b/Adam_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global/rnn/basic_lstm_cell/kernel, global/rnn/basic_lstm_cell/bias, global/action/w, global/action/b, global/value/w, global/value/b, global/global_step, global/global_episode, beta1_power, beta2_power, global/rnn/basic_lstm_cell/kernel/Adam, global/rnn/basic_lstm_cell/kernel/Adam_1, global/rnn/basic_lstm_cell/bias/Adam, global/rnn/basic_lstm_cell/bias/Adam_1, global/action/w/Adam, global/action/w/Adam_1, global/action/b/Adam, global/action/b/Adam_1, global/value/w/Adam, global/value/w/Adam_1, global/value/b/Adam, global/value/b/Adam_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:19,809] Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global/rnn/basic_lstm_cell/kernel, global/rnn/basic_lstm_cell/bias, global/action/w, global/action/b, global/value/w, global/value/b, global/global_step, global/global_episode, beta1_power, beta2_power, global/rnn/basic_lstm_cell/kernel/Adam, global/rnn/basic_lstm_cell/kernel/Adam_1, global/rnn/basic_lstm_cell/bias/Adam, global/rnn/basic_lstm_cell/bias/Adam_1, global/action/w/Adam, global/action/w/Adam_1, global/action/b/Adam, global/action/b/Adam_1, global/value/w/Adam, global/value/w/Adam_1, global/value/b/Adam, global/value/b/Adam_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:19,871] Starting queue runners.\n",
      "[2017-08-24 22:26:19,844] Starting queue runners.\n",
      "[2017-08-24 22:26:19,988] worker_7: starting training at step: 0\n",
      "[2017-08-24 22:26:19,988] worker_4: starting training at step: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting standard services.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:22,659] Starting standard services.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_2/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:22,677] Saving checkpoint to path ./tmp/a3c_testing_2/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:global/global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 22:26:22,678] Starting queue runners.\n",
      "[2017-08-24 22:26:22,679] global/global_step/sec: 0\n",
      "[2017-08-24 22:26:22,706] worker_0: starting training at step: 302\n",
      "Process BTgymDataFeedServer-11:1:\n",
      "Process BTgymServer-15:1:\n",
      "Process BTgymServer-18:1:\n",
      "Process DrawCerebro-11:2:5:\n",
      "Process BTgymServer-13:1:\n",
      "Process BTgymServer-17:1:\n",
      "Process BTgymServer-16:1:\n",
      "[2017-08-24 22:26:37,197] worker_1 has joined.\n",
      "[2017-08-24 22:26:37,199] worker_2 has joined.\n",
      "Process BTgymServer-12:1:\n",
      "Process BTgymServer-14:1:\n",
      "[2017-08-24 22:26:37,211] worker_3 has joined.\n",
      "[2017-08-24 22:26:37,212] worker_4 has joined.\n",
      "[2017-08-24 22:26:37,213] worker_5 has joined.\n",
      "[2017-08-24 22:26:37,214] worker_6 has joined.\n",
      "[2017-08-24 22:26:37,215] worker_7 has joined.\n",
      "Traceback (most recent call last):\n",
      "[2017-08-24 22:26:37,217] chief_worker_0 has joined.\n",
      "[2017-08-24 22:26:37,218] parameter_server_0 has joined.\n",
      "[2017-08-24 22:26:37,219] Launcher closed.\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/dataserver.py\", line 100, in run\n",
      "    service_input = socket.recv_pyobj()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/zmq/sugar/socket.py\", line 491, in recv_pyobj\n",
      "    msg = self.recv(flags)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 693, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 727, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 145, in zmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 318, in run\n",
      "    service_input = socket.recv_pyobj()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/zmq/sugar/socket.py\", line 491, in recv_pyobj\n",
      "    msg = self.recv(flags)\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 318, in run\n",
      "    service_input = socket.recv_pyobj()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 318, in run\n",
      "    service_input = socket.recv_pyobj()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 318, in run\n",
      "    service_input = socket.recv_pyobj()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/zmq/sugar/socket.py\", line 491, in recv_pyobj\n",
      "    msg = self.recv(flags)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 318, in run\n",
      "    service_input = socket.recv_pyobj()\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 693, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/zmq/sugar/socket.py\", line 491, in recv_pyobj\n",
      "    msg = self.recv(flags)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 727, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 693, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 727, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/zmq/sugar/socket.py\", line 491, in recv_pyobj\n",
      "    msg = self.recv(flags)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 693, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 145, in zmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 693, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 413, in run\n",
      "    episode = cerebro.run(stdstats=True, preload=False, oldbuysell=True)[0]\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 145, in zmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1073, in run\n",
      "    runstrat = self.runstrategies(iterstrat)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1235, in runstrategies\n",
      "    self._runnext(runstrats)\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/zmq/sugar/socket.py\", line 491, in recv_pyobj\n",
      "    msg = self.recv(flags)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 727, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1564, in _runnext\n",
      "    strat._next()\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 145, in zmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/strategy.py\", line 327, in _next\n",
      "    self._next_analyzers(minperstatus)\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/strategy.py\", line 361, in _next_analyzers\n",
      "    analyzer._next()\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 727, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/analyzer.py\", line 188, in _next\n",
      "    self.next()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 109, in next\n",
      "    self.message = self.socket.recv_pyobj()\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\n",
      "KeyboardInterrupt\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 145, in zmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 693, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\n",
      "KeyboardInterrupt\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 727, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/zmq/sugar/socket.py\", line 491, in recv_pyobj\n",
      "    msg = self.recv(flags)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 145, in zmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 693, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 727, in zmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 145, in zmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 413, in run\n",
      "    episode = cerebro.run(stdstats=True, preload=False, oldbuysell=True)[0]\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1073, in run\n",
      "    runstrat = self.runstrategies(iterstrat)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1235, in runstrategies\n",
      "    self._runnext(runstrats)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 1564, in _runnext\n",
      "    strat._next()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/strategy.py\", line 327, in _next\n",
      "    self._next_analyzers(minperstatus)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/strategy.py\", line 361, in _next_analyzers\n",
      "    analyzer._next()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/analyzer.py\", line 188, in _next\n",
      "    self.next()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/server.py\", line 103, in next\n",
      "    state = self.strategy.get_state()\n",
      "  File \"<ipython-input-7-6969c18476ec>\", line 50, in get_state\n",
      "    X = signal.cwt(X, signal.ricker, cwt_width).T\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/scipy/signal/wavelets.py\", line 362, in cwt\n",
      "    wavelet_data = wavelet(min(10 * width, len(data)), width)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/scipy/signal/wavelets.py\", line 305, in ricker\n",
      "    mod = (1 - xsq / wsq)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/muzikin/Yandex.Disk.localized/work/btgym/btgym/rendering/plotter.py\", line 73, in run\n",
      "    figfilename='_tmp_btgym_render.png',\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/cerebro.py\", line 930, in plot\n",
      "    start=start, end=end, use=use)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/plot/plot.py\", line 222, in plot\n",
      "    self.plotdata(data, self.dplotsover[data])\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/backtrader/plot/plot.py\", line 631, in plotdata\n",
      "    ax = axvol.twinx()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axes/_base.py\", line 3861, in twinx\n",
      "    ax2 = self._make_twin_axes(sharex=self)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axes/_subplots.py\", line 153, in _make_twin_axes\n",
      "    *kl, **kwargs)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axes/_subplots.py\", line 73, in __init__\n",
      "    self._axes_class.__init__(self, fig, self.figbox, **kwargs)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axes/_base.py\", line 551, in __init__\n",
      "    self.cla()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axes/_base.py\", line 984, in cla\n",
      "    spine.cla()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/spines.py\", line 170, in cla\n",
      "    self.axis.cla()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axis.py\", line 760, in cla\n",
      "    self.reset_ticks()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axis.py\", line 775, in reset_ticks\n",
      "    self.minorTicks.extend([self._get_tick(major=False)])\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axis.py\", line 1729, in _get_tick\n",
      "    return XTick(self.axes, 0, '', major=major, **tick_kw)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axis.py\", line 151, in __init__\n",
      "    self.tick2line = self._get_tick2line()\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/axis.py\", line 434, in _get_tick2line\n",
      "    zorder=self._zorder)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/lines.py\", line 431, in __init__\n",
      "    self.update(kwargs)\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/artist.py\", line 885, in update\n",
      "    for k, v in props.items()]\n",
      "  File \"/Users/muzikin/anaconda/envs/tensorforce/lib/python3.6/site-packages/matplotlib/artist.py\", line 884, in <listcomp>\n",
      "    ret = [_update_property(self, k, v)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "launcher.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(launcher.kwargs, '\\n\\n')\n",
    "print(launcher.env_config)\n",
    "print(launcher.cluster_config)\n",
    "print(launcher.cluster_spec)\n",
    "for config in launcher.workers_config_list:\n",
    "    print('============')\n",
    "    for k, v in config.items():\n",
    "        print('{}:\\n{}\\n'.format(k, v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func1(max_step):\n",
    "    step = 0\n",
    "    done = False\n",
    "    \n",
    "    def func2(max_step):\n",
    "        nonlocal step\n",
    "        nonlocal done\n",
    "        step +=1\n",
    "        if step == max_step:\n",
    "            step = 0\n",
    "            done = True\n",
    "        return step\n",
    "    \n",
    "    for i in range(20):\n",
    "        done = False\n",
    "        print(func2(max_step), step, done)\n",
    "        \n",
    "\n",
    "\n",
    "func1(7)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = dict()\n",
    "a.update({'b': 2, 'c':4})\n",
    "type(a) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
