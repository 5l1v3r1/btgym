{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "#import sys\n",
    "#sys.path.insert(0,'..')\n",
    "\n",
    "import os\n",
    "\n",
    "import backtrader as bt\n",
    "import backtrader.indicators as btind\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from scipy import stats\n",
    "\n",
    "from gym import spaces\n",
    "\n",
    "from btgym import BTgymEnv, BTgymStrategy, BTgymDataset\n",
    "\n",
    "from launcher import Launcher\n",
    "from model import LSTMPolicy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "from tensorflow.contrib.layers import flatten as flatten_on_batch\n",
    "from tensorflow.python.util.nest import flatten as flatten_nested\n",
    "\n",
    "class LSTMPolicy2(object):\n",
    "    \"\"\"\n",
    "    Policy estimator with multi-layer LSTM cells. \n",
    "    \"\"\"\n",
    "    def __init__(self, ob_space, ac_space, lstm_class=rnn.LSTMCell, lstm_sizes=(256,)):\n",
    "\n",
    "        self.x = x = tf.placeholder(tf.float32, [None] + list(ob_space), name='x_in_pl')\n",
    "        \n",
    "        # Conv layers, features here:\n",
    "        for i in range(4):\n",
    "            x = tf.nn.elu(self.conv2d(x, 32, \"l{}\".format(i + 1), [3, 3], [2, 2]))\n",
    "                 \n",
    "        # Flatten to feed to LSTM babk:\n",
    "        x = tf.expand_dims(flatten_on_batch(x), [0])\n",
    "        \n",
    "        print('flatten_x_shape:', x.shape)\n",
    "        \n",
    "        # Define LSTM layers:\n",
    "        lstm = []\n",
    "        for size in lstm_sizes:\n",
    "            lstm += [lstm_class(size, state_is_tuple=True)]\n",
    "\n",
    "        #self.lstm = rnn.MultiRNNCell(lstm, state_is_tuple=True)\n",
    "        self.lstm = lstm[0]\n",
    "        \n",
    "        state_size = self.lstm.state_size\n",
    "        step_size = tf.shape(x)[:1]\n",
    "        print('step_size:', step_size)\n",
    "        \n",
    "        self.lstm_init_state = self.lstm.zero_state(1, dtype=tf.float32)\n",
    "\n",
    "        lstm_state_pl = self.rnn_placeholders(self.lstm.zero_state(1, dtype=tf.float32))\n",
    "        self.lstm_state_pl_flatten = flatten_nested(lstm_state_pl)\n",
    "\n",
    "        print('lstm_state_pl :', lstm_state_pl )\n",
    "\n",
    "        lstm_outputs, self.lstm_state_out = tf.nn.dynamic_rnn(\n",
    "            self.lstm,\n",
    "            x,\n",
    "            initial_state=lstm_state_pl,\n",
    "            sequence_length=step_size,\n",
    "            time_major=False\n",
    "        )\n",
    "\n",
    "        x = tf.reshape(lstm_outputs, [-1, size])\n",
    "        \n",
    "        print('x_shape_before_logits:', x.shape)\n",
    "                 \n",
    "        self.logits = self.linear(x, ac_space, \"action\", self.normalized_columns_initializer(0.01))\n",
    "        self.vf = tf.reshape(self.linear(x, 1, \"value\", self.normalized_columns_initializer(1.0)), [-1])\n",
    "        #self.state_out = [lstm_c[:1, :], lstm_h[:1, :]]\n",
    "        self.sample = self.categorical_sample(self.logits, ac_space)[0, :]\n",
    "        self.var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, tf.get_variable_scope().name)\n",
    "\n",
    "        \n",
    "    def get_initial_state(self):\n",
    "        sess = tf.get_default_session()\n",
    "        return sess.run(self.lstm_init_state)\n",
    "\n",
    "    def act(self, ob, lstm_state):\n",
    "        sess = tf.get_default_session()\n",
    "        feeder = {pl: value for pl, value in zip(self.lstm_state_pl_flatten, flatten_nested(lstm_state))}\n",
    "        feeder.update({self.x: [ob]})\n",
    "        return sess.run([self.sample, self.vf, self.lstm_state_out], feeder)\n",
    "    \n",
    "    def value(self, ob, lstm_state):\n",
    "        sess = tf.get_default_session()\n",
    "        feeder = {pl: value for pl, value in zip(self.lstm_state_pl_flatten, flatten_nested(lstm_state))}\n",
    "        feeder.update({self.x: [ob]})\n",
    "        return sess.run(self.vf, feeder)[0]\n",
    "                 \n",
    "    def normalized_columns_initializer(self, std=1.0):\n",
    "        def _initializer(shape, dtype=None, partition_info=None):\n",
    "            out = np.random.randn(*shape).astype(np.float32)\n",
    "            out *= std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "            return tf.constant(out)\n",
    "\n",
    "        return _initializer\n",
    "                 \n",
    "    def conv2d(self, x, num_filters, name, filter_size=(3, 3), stride=(1, 1), pad=\"SAME\", dtype=tf.float32, collections=None):\n",
    "        with tf.variable_scope(name):\n",
    "            stride_shape = [1, stride[0], stride[1], 1]\n",
    "            filter_shape = [filter_size[0], filter_size[1], int(x.get_shape()[3]), num_filters]\n",
    "\n",
    "            # there are \"num input feature maps * filter height * filter width\"\n",
    "            # inputs to each hidden unit\n",
    "            fan_in = np.prod(filter_shape[:3])\n",
    "            # each unit in the lower layer receives a gradient from:\n",
    "            # \"num output feature maps * filter height * filter width\" /\n",
    "            #   pooling size\n",
    "            fan_out = np.prod(filter_shape[:2]) * num_filters\n",
    "            # initialize weights with random weights\n",
    "            w_bound = np.sqrt(6. / (fan_in + fan_out))\n",
    "\n",
    "            w = tf.get_variable(\"W\", filter_shape, dtype, tf.random_uniform_initializer(-w_bound, w_bound),\n",
    "                                collections=collections)\n",
    "            b = tf.get_variable(\"b\", [1, 1, 1, num_filters], initializer=tf.constant_initializer(0.0),\n",
    "                                collections=collections)\n",
    "            return tf.nn.conv2d(x, w, stride_shape, pad) + b\n",
    "\n",
    "    def linear(self, x, size, name, initializer=None, bias_init=0):\n",
    "        w = tf.get_variable(name + \"/w\", [x.get_shape()[1], size], initializer=initializer)\n",
    "        b = tf.get_variable(name + \"/b\", [size], initializer=tf.constant_initializer(bias_init))\n",
    "        return tf.matmul(x, w) + b\n",
    "\n",
    "    def categorical_sample(self, logits, d):\n",
    "        value = tf.squeeze(tf.multinomial(logits - tf.reduce_max(logits, [1], keep_dims=True), 1), [1])\n",
    "        return tf.one_hot(value, d)\n",
    "            \n",
    "    def rnn_placeholders(self, state):\n",
    "        \"\"\"\n",
    "        Converts RNN state tensors to placeholders with the zero state as default.\n",
    "        \"\"\"\n",
    "        if isinstance(state, tf.contrib.rnn.LSTMStateTuple):\n",
    "            c, h = state\n",
    "            c = tf.placeholder_with_default(c, c.shape, c.op.name + '_pl')\n",
    "            print('c_shape:', c.shape)\n",
    "            h = tf.placeholder_with_default(h, h.shape, h.op.name + '_pl')\n",
    "            return tf.contrib.rnn.LSTMStateTuple(c, h)\n",
    "        elif isinstance(state, tf.Tensor):\n",
    "            h = state\n",
    "            h = tf.placeholder_with_default(h, h.shape, h.op.name + '_pl')\n",
    "            return h\n",
    "        else:\n",
    "            structure = [self.rnn_placeholders(x) for x in state]\n",
    "            return tuple(structure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:15,208] ./tmp/a3c_testing_gym created.\n",
      "[2017-08-27 13:21:16,145] Launcher ready.\n"
     ]
    }
   ],
   "source": [
    "# GYM TEST ENV:\n",
    "cluster_config = dict(\n",
    "    host='127.0.0.1',\n",
    "    port=22222,\n",
    "    num_workers=8,\n",
    "    num_ps=1,\n",
    "    log_dir='./tmp/a3c_testing_gym',\n",
    ")\n",
    "\n",
    "env_config = dict(\n",
    "    gym_id='Breakout-v0'\n",
    ")\n",
    "\n",
    "launcher = Launcher(\n",
    "    cluster_config=cluster_config,\n",
    "    env_config=env_config,\n",
    "    model_class=LSTMPolicy2,\n",
    "    train_steps=500000000,\n",
    "    opt_learn_rate=1e-4,\n",
    "    rollout_length=20,\n",
    "    test_mode=True,\n",
    "    model_summary_freq=50,\n",
    "    episode_summary_freq=2,\n",
    "    env_render_freq=10,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:17,667] worker_0 tf.server started.\n",
      "[2017-08-27 13:21:17,709] parameters_server started.\n",
      "[2017-08-27 13:21:17,733] making environment.\n",
      "[2017-08-27 13:21:17,791] Making new env: Breakout-v0\n",
      "[2017-08-27 13:21:18,250] worker_0:envronment ok.\n",
      "[2017-08-27 13:21:18,252] A3C_0: init() started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_x_shape: (1, ?, 288)\n",
      "step_size: Tensor(\"global/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:0/device:CPU:0)\n",
      "c_shape: (1, 256)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "x_shape_before_logits: (?, 256)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "step_size: Tensor(\"local/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:0/device:CPU:0)\n",
      "c_shape: (1, 256)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "x_shape_before_logits: (?, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:22,130] A3C_0: train op defined\n",
      "[2017-08-27 13:21:22,287] A3C_0: init() done\n",
      "[2017-08-27 13:21:22,289] worker_0:trainer ok.\n",
      "[2017-08-27 13:21:22,669] Press `Ctrl-C` to stop training and close launcher.\n",
      "[2017-08-27 13:21:22,698] worker_1 tf.server started.\n",
      "[2017-08-27 13:21:22,701] worker_2 tf.server started.\n",
      "[2017-08-27 13:21:22,729] making environment.\n",
      "[2017-08-27 13:21:22,730] making environment.\n",
      "[2017-08-27 13:21:22,749] worker_3 tf.server started.\n",
      "[2017-08-27 13:21:22,750] worker_7 tf.server started.\n",
      "[2017-08-27 13:21:22,749] worker_5 tf.server started.\n",
      "[2017-08-27 13:21:22,750] worker_6 tf.server started.\n",
      "[2017-08-27 13:21:22,763] making environment.\n",
      "[2017-08-27 13:21:22,754] worker_4 tf.server started.\n",
      "[2017-08-27 13:21:22,763] making environment.\n",
      "[2017-08-27 13:21:22,763] making environment.\n",
      "[2017-08-27 13:21:22,765] making environment.\n",
      "[2017-08-27 13:21:22,747] Making new env: Breakout-v0\n",
      "[2017-08-27 13:21:22,773] making environment.\n",
      "[2017-08-27 13:21:22,759] Making new env: Breakout-v0\n",
      "[2017-08-27 13:21:22,772] Making new env: Breakout-v0\n",
      "[2017-08-27 13:21:22,772] Making new env: Breakout-v0\n",
      "[2017-08-27 13:21:22,771] Making new env: Breakout-v0\n",
      "[2017-08-27 13:21:22,775] Making new env: Breakout-v0\n",
      "[2017-08-27 13:21:22,783] Making new env: Breakout-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press `Ctrl-C` to stop training and close launcher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:22,935] worker_1:envronment ok.\n",
      "[2017-08-27 13:21:22,938] worker_2:envronment ok.\n",
      "[2017-08-27 13:21:22,943] A3C_1: init() started\n",
      "[2017-08-27 13:21:22,944] worker_6:envronment ok.\n",
      "[2017-08-27 13:21:22,952] A3C_6: init() started\n",
      "[2017-08-27 13:21:22,947] worker_3:envronment ok.\n",
      "[2017-08-27 13:21:22,944] A3C_2: init() started\n",
      "[2017-08-27 13:21:22,955] worker_7:envronment ok.\n",
      "[2017-08-27 13:21:22,957] worker_4:envronment ok.\n",
      "[2017-08-27 13:21:22,947] worker_5:envronment ok.\n",
      "[2017-08-27 13:21:22,960] A3C_3: init() started\n",
      "[2017-08-27 13:21:22,963] A3C_7: init() started\n",
      "[2017-08-27 13:21:22,962] A3C_4: init() started\n",
      "[2017-08-27 13:21:22,964] A3C_5: init() started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_x_shape: (1, ?, 288)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "step_size: Tensor(\"global/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:1/device:CPU:0)\n",
      "step_size: Tensor(\"global/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:3/device:CPU:0)\n",
      "step_size: Tensor(\"global/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:6/device:CPU:0)\n",
      "step_size: Tensor(\"global/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:7/device:CPU:0)\n",
      "step_size: Tensor(\"global/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:5/device:CPU:0)\n",
      "step_size: Tensor(\"global/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:2/device:CPU:0)\n",
      "step_size: Tensor(\"global/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:4/device:CPU:0)\n",
      "c_shape: (1, 256)\n",
      "c_shape: (1, 256)\n",
      "c_shape: (1, 256)\n",
      "c_shape: (1, 256)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "c_shape: (1, 256)\n",
      "c_shape: (1, 256)\n",
      "c_shape: (1, 256)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'global/global/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:24,378] connecting to the parameter server... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_x_shape: (1, ?, 288)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "step_size: Tensor(\"local/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:5/device:CPU:0)\n",
      "step_size: Tensor(\"local/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:3/device:CPU:0)\n",
      "c_shape: (1, 256)\n",
      "c_shape: (1, 256)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "step_size: Tensor(\"local/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:1/device:CPU:0)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "step_size: Tensor(\"local/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:7/device:CPU:0)\n",
      "step_size: Tensor(\"local/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:2/device:CPU:0)\n",
      "flatten_x_shape: (1, ?, 288)\n",
      "step_size: Tensor(\"local/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:6/device:CPU:0)\n",
      "step_size: Tensor(\"local/strided_slice:0\", shape=(1,), dtype=int32, device=/job:worker/task:4/device:CPU:0)\n",
      "c_shape: (1, 256)\n",
      "c_shape: (1, 256)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "c_shape: (1, 256)\n",
      "c_shape: (1, 256)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "c_shape: (1, 256)\n",
      "lstm_state_pl : LSTMStateTuple(c=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_pl:0' shape=(1, 256) dtype=float32>, h=<tf.Tensor 'local/local/LSTMCellZeroState_1/zeros_1_pl:0' shape=(1, 256) dtype=float32>)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n",
      "x_shape_before_logits: (?, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:26,051] Initializing all parameters.\n",
      "[2017-08-27 13:21:26,590] A3C_5: train op defined\n",
      "[2017-08-27 13:21:26,630] A3C_3: train op defined\n",
      "[2017-08-27 13:21:26,739] A3C_1: train op defined\n",
      "[2017-08-27 13:21:26,762] A3C_2: train op defined\n",
      "[2017-08-27 13:21:26,774] A3C_7: train op defined\n",
      "[2017-08-27 13:21:26,798] A3C_6: train op defined\n",
      "[2017-08-27 13:21:26,824] A3C_4: train op defined\n",
      "[2017-08-27 13:21:26,965] A3C_5: init() done\n",
      "[2017-08-27 13:21:26,972] worker_5:trainer ok.\n",
      "[2017-08-27 13:21:27,005] A3C_3: init() done\n",
      "[2017-08-27 13:21:27,028] worker_3:trainer ok.\n",
      "[2017-08-27 13:21:27,127] A3C_1: init() done\n",
      "[2017-08-27 13:21:27,129] worker_1:trainer ok.\n",
      "[2017-08-27 13:21:27,152] A3C_2: init() done\n",
      "[2017-08-27 13:21:27,154] worker_2:trainer ok.\n",
      "[2017-08-27 13:21:27,161] A3C_7: init() done\n",
      "[2017-08-27 13:21:27,163] worker_7:trainer ok.\n",
      "[2017-08-27 13:21:27,190] A3C_6: init() done\n",
      "[2017-08-27 13:21:27,192] worker_6:trainer ok.\n",
      "[2017-08-27 13:21:27,201] A3C_4: init() done\n",
      "[2017-08-27 13:21:27,209] worker_4:trainer ok.\n",
      "[2017-08-27 13:21:28,944] connecting to the parameter server... \n",
      "[2017-08-27 13:21:29,044] connecting to the parameter server... \n",
      "[2017-08-27 13:21:29,096] connecting to the parameter server... \n",
      "[2017-08-27 13:21:29,121] connecting to the parameter server... \n",
      "[2017-08-27 13:21:29,119] connecting to the parameter server... \n",
      "[2017-08-27 13:21:29,127] connecting to the parameter server... \n",
      "[2017-08-27 13:21:29,191] connecting to the parameter server... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:30,375] Starting queue runners.\n",
      "[2017-08-27 13:21:30,418] worker_5: starting training at step: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:30,459] Starting queue runners.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:30,535] worker_3: starting training at step: 0\n",
      "[2017-08-27 13:21:30,555] Starting queue runners.\n",
      "[2017-08-27 13:21:30,554] Starting queue runners.\n",
      "[2017-08-27 13:21:30,643] worker_7: starting training at step: 0\n",
      "[2017-08-27 13:21:30,645] worker_6: starting training at step: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:30,683] Starting queue runners.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:30,703] Starting queue runners.\n",
      "[2017-08-27 13:21:30,683] Starting queue runners.\n",
      "[2017-08-27 13:21:30,738] worker_4: starting training at step: 0\n",
      "[2017-08-27 13:21:30,732] worker_2: starting training at step: 0\n",
      "[2017-08-27 13:21:30,744] worker_1: starting training at step: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting standard services.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:32,669] Starting standard services.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:32,710] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:32,732] Starting queue runners.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:21:32,756] global/global_step/sec: 0\n",
      "[2017-08-27 13:21:32,867] worker_0: starting training at step: 700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 523.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:23:32,768] global/global_step/sec: 523.696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 545.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:25:32,741] global/global_step/sec: 545.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:26:32,701] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 518.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:27:32,738] global/global_step/sec: 518.238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 531.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:29:32,739] global/global_step/sec: 531.304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:31:32,700] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 516.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:31:32,771] global/global_step/sec: 516.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 523.096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:33:32,743] global/global_step/sec: 523.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 526.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:35:32,781] global/global_step/sec: 526.832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:36:32,697] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 514.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:37:32,738] global/global_step/sec: 514.827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global/global_step/sec: 521.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:39:32,742] global/global_step/sec: 521.483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:41:32,697] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:46:32,697] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:51:32,699] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 13:56:32,698] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:01:32,697] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:06:32,699] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:11:32,700] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:16:32,698] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:21:32,697] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:26:32,699] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:31:32,702] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:36:32,700] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:41:32,697] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:46:32,697] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:51:32,697] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 14:56:32,703] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 15:01:32,706] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 15:06:32,707] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 15:11:32,703] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 15:16:32,706] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 15:21:32,701] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 15:26:32,707] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-27 15:31:32,701] Saving checkpoint to path ./tmp/a3c_testing_gym/train/model.ckpt\n",
      "[2017-08-27 15:34:04,315] worker_1 has joined.\n",
      "[2017-08-27 15:34:04,328] worker_2 has joined.\n",
      "[2017-08-27 15:34:04,329] worker_3 has joined.\n",
      "[2017-08-27 15:34:04,330] worker_4 has joined.\n",
      "[2017-08-27 15:34:04,331] worker_5 has joined.\n",
      "[2017-08-27 15:34:04,332] worker_6 has joined.\n",
      "[2017-08-27 15:34:04,357] worker_7 has joined.\n",
      "[2017-08-27 15:34:04,358] chief_worker_0 has joined.\n",
      "[2017-08-27 15:34:04,359] parameter_server_0 has joined.\n",
      "[2017-08-27 15:34:04,360] Launcher closed.\n"
     ]
    }
   ],
   "source": [
    "launcher.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyStrategy(BTgymStrategy):\n",
    "    \"\"\"\n",
    "    Example subclass of BT server inner computation startegy.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.log = self.env._log\n",
    "        \n",
    "        self.data.dim_sma = btind.SimpleMovingAverage(self.datas[0], period=5)\n",
    "        self.data.dim_sma.plotinfo.plot = False\n",
    "\n",
    "        self.target_value = self.env.broker.startingcash * (1 + self.p.target_call / 100)\n",
    "        \n",
    "        self.current_value_embeded = np.ones(self.p.state_shape['raw_state'].shape[0]) * \\\n",
    "            self.p.target_call / (self.p.target_call + self.p.drawdown_call )\n",
    "\n",
    "        self.order_penalty = 1\n",
    "        self.trade_just_closed = False\n",
    "        self.trade_result = None\n",
    "        \n",
    "        self.channel = 3\n",
    "        self.x_buffer = np.ones(self.p.state_shape['raw_state'].shape[0])\n",
    "        \n",
    "    def nextstart(self):\n",
    "        self.inner_embedding = self.data.close.buflen()\n",
    "        self.log.debug('Inner time embedding: {}'.format(self.inner_embedding))\n",
    "        self.x_buffer *= self.data.close[0]\n",
    "        \n",
    "    def notify_trade(self, trade):\n",
    "        #if trade.justopened:\n",
    "            #print('trade {} just opened'.format(trade.ref))\n",
    "            \n",
    "        if trade.isclosed:\n",
    "            #print('trade {} closed, pnl_comm: {}'.format(trade.ref, trade.pnlcomm))\n",
    "            # Set trade flag and result:\n",
    "            self.trade_just_closed = True\n",
    "            self.trade_result = trade.pnlcomm\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "        \n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Computes featurized RL-ready environment observation state\n",
    "        by applying continious wavelet transform to time-embedded vector\n",
    "        of close-price gradients.\n",
    "        \"\"\"\n",
    "        # Use close price:\n",
    "        \n",
    "        \n",
    "        #X = self.raw_state[:, self.channel]\n",
    "        X = self.x_buffer\n",
    "        \n",
    "        # Prepare parameters:\n",
    "        Tau = 2\n",
    "        max_cwt_scale = self.p.state_shape['model_input'].shape[1] #- 1\n",
    "        cwt_width = np.linspace(Tau, max_cwt_scale + Tau - 1, max_cwt_scale) # scale of wavelet transdorm [n]\n",
    "    \n",
    "        T = 1e4\n",
    "        \n",
    "        # Get vector of gradients of last [n] prices:\n",
    "        X = np.gradient(X, axis=0) * T\n",
    "        \n",
    "        # Compute continious wavelet transform using Ricker wavelet, get [n,m,1]-dim. matrix:\n",
    "        X = signal.cwt(X, signal.ricker, cwt_width).T + 1\n",
    "\n",
    "        #print('X:', X.shape)\n",
    "        #print('self.current_value_embeded:', self.current_value_embeded.shape)\n",
    "        \n",
    "        #self.state['model_input'] = np.concatenate([X, self.current_value_embeded[:, None] ], axis=-1)\n",
    "        self.state['model_input'] = X[-self.p.state_shape['model_input'].shape[0]:, :]\n",
    "        \n",
    "        #print('model_input:', self.state['model_input'].shape)\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    \n",
    "    def get_reward(self):\n",
    "        \"\"\"\n",
    "        Defines reward as function of last closed trade result.\n",
    "        \"\"\"\n",
    "        #r = 0\n",
    "        \n",
    "        r = (self.broker.get_value() / self.env.broker.startingcash - 1) * 10\n",
    "        \n",
    "        # Result\n",
    "        if self.trade_just_closed:\n",
    "            r += self.trade_result\n",
    "            self.trade_just_closed = False\n",
    "            #print('R-trade:', r)\n",
    "            \n",
    "        # Penalty for failed order:\n",
    "\n",
    "        r -= self.order_penalty * self.order_failed\n",
    "        self.order_failed = 0\n",
    "\n",
    "            \n",
    "        #print('reward_', r)\n",
    "        \n",
    "        return r / 10\n",
    "    \n",
    "    def next(self):\n",
    "        \"\"\"\n",
    "        Extension of default implementation.\n",
    "        Defines one step environment routine for server 'Episode mode';\n",
    "        At least, it should handle order execution logic according to action received.\n",
    "        \"\"\"\n",
    "        # Normalized time-embedded vector of broker values:\n",
    "        self.current_value_embeded = np.roll(self.current_value_embeded, -1)\n",
    "        \n",
    "        self.x_buffer = np.roll(self.x_buffer, -1)\n",
    "        \n",
    "        self.current_value_embeded[-1] =\\\n",
    "            (self.broker.get_value() / self.env.broker.startingcash - 1 + self.p.drawdown_call / 100) / \\\n",
    "            (self.p.target_call + self.p.drawdown_call) * 100\n",
    "            \n",
    "        self.x_buffer[-1] = self.data.close[0]\n",
    "        \n",
    "        # Simple action-to-order logic:\n",
    "        if self.action == 'hold' or self.order:\n",
    "            pass\n",
    "        elif self.action == 'buy':\n",
    "            self.order = self.buy()\n",
    "            self.broker_message = 'New BUY created; ' + self.broker_message\n",
    "        elif self.action == 'sell':\n",
    "            self.order = self.sell()\n",
    "            self.broker_message = 'New SELL created; ' + self.broker_message\n",
    "        elif self.action == 'close':\n",
    "            self.order = self.close()\n",
    "            self.broker_message = 'New CLOSE created; ' + self.broker_message\n",
    "            \n",
    "# Set backtesting engine parameters:\n",
    "time_embed_dim = 30\n",
    "state_shape = {\n",
    "    'raw_state': spaces.Box(low=-1, high=1, shape=(2*time_embed_dim, 4)),\n",
    "    'model_input': spaces.Box(low=-100, high=100, shape=(time_embed_dim, time_embed_dim))\n",
    "}\n",
    "\n",
    "MyCerebro = bt.Cerebro()\n",
    "\n",
    "MyCerebro.addstrategy(\n",
    "    MyStrategy,\n",
    "    state_shape=state_shape,\n",
    "    portfolio_actions=('hold', 'buy', 'sell'),\n",
    "    drawdown_call=5, # in percent of initial cash\n",
    "    target_call=20,\n",
    "    skip_frame=10,\n",
    ")\n",
    "\n",
    "# Set leveraged account:\n",
    "MyCerebro.broker.setcash(2000)\n",
    "MyCerebro.broker.setcommission(commission=0.0001, leverage=10.0)\n",
    "MyCerebro.broker.set_shortcash(False)\n",
    "MyCerebro.addsizer(bt.sizers.SizerFix, stake=10000,)\n",
    "\n",
    "\n",
    "MyCerebro.addanalyzer(bt.analyzers.DrawDown)\n",
    "\n",
    "# Provide data (seven years of 1 minute bars):\n",
    "filenames = [\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2010.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2011.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2012.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2013.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2014.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2015.csv',\n",
    "    '../data/DAT_ASCII_EURUSD_M1_2016.csv',\n",
    "]\n",
    "\n",
    "MyDataset = BTgymDataset(\n",
    "    #filename=filenames,\n",
    "    #filename='../data/test_sine_1min_period256_delta0002.csv',\n",
    "    filename='../data/DAT_ASCII_EURUSD_M1_2016.csv',\n",
    "    start_weekdays=[0, 1, 2, 3, 4],\n",
    "    episode_len_days=0,\n",
    "    episode_len_hours=23,\n",
    "    episode_len_minutes=0,\n",
    "    start_00=False,\n",
    "    time_gap_hours=6,\n",
    ")\n",
    "env_config = dict(\n",
    "    dataset=MyDataset,\n",
    "    engine=MyCerebro,\n",
    "    render_modes=['episode', 'human', 'model_input'],\n",
    "    render_state_as_image=False,\n",
    "    render_ylabel='CWT transform',\n",
    "    render_size_episode=(12,8),\n",
    "    render_size_human=(8, 3.5),\n",
    "    render_size_state=(10, 5),\n",
    "    render_dpi=75,\n",
    "    port=5000,\n",
    "    data_port=4999,\n",
    "    connect_timeout=60,\n",
    "    verbose=0,\n",
    ")\n",
    "cluster_config = dict(\n",
    "    host='127.0.0.1',\n",
    "    port=12222,\n",
    "    num_workers=8,\n",
    "    num_ps=1,\n",
    "    log_dir='./tmp/a3c_testing_7',\n",
    ")\n",
    "launcher = Launcher(\n",
    "    cluster_config=cluster_config,\n",
    "    env_class=BTgymEnv,\n",
    "    env_config=env_config,\n",
    "    model_class=SimpleLSTM,\n",
    "    rollout_length=20,\n",
    "    test_mode=False,\n",
    "    train_steps=1000000000,\n",
    "    model_summary_freq=20,\n",
    "    episode_summary_freq=1,\n",
    "    env_render_freq=20,\n",
    "    verbose=1\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "launcher.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(launcher.kwargs, '\\n\\n')\n",
    "print(launcher.env_config)\n",
    "print(launcher.cluster_config)\n",
    "print(launcher.cluster_spec)\n",
    "for config in launcher.workers_config_list:\n",
    "    print('============')\n",
    "    for k, v in config.items():\n",
    "        print('{}:\\n{}\\n'.format(k, v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func1(max_step):\n",
    "    step = 0\n",
    "    done = False\n",
    "    \n",
    "    def func2(max_step):\n",
    "        nonlocal step\n",
    "        nonlocal done\n",
    "        step +=1\n",
    "        if step == max_step:\n",
    "            step = 0\n",
    "            done = True\n",
    "        return step\n",
    "    \n",
    "    for i in range(20):\n",
    "        done = False\n",
    "        print(func2(max_step), step, done)\n",
    "        \n",
    "\n",
    "\n",
    "func1(7)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = dict()\n",
    "a.update({'b': 2, 'c':4})\n",
    "type(a) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
