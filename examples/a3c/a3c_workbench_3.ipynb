{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "#import sys\n",
    "#sys.path.insert(0,'..')\n",
    "\n",
    "import os\n",
    "\n",
    "import backtrader as bt\n",
    "import backtrader.indicators as btind\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "\n",
    "from gym import spaces\n",
    "\n",
    "from btgym import BTgymEnv, BTgymStrategy, BTgymDataset\n",
    "\n",
    "from launcher import Launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GYM TEST ENV:\n",
    "cluster_config = dict(\n",
    "    host='127.0.0.1',\n",
    "    port=12222,\n",
    "    num_workers=8,\n",
    "    num_ps=1,\n",
    "    log_dir='./tmp/a3c_testing_gym',\n",
    ")\n",
    "\n",
    "env_config = dict(\n",
    "    gym_id='Breakout-v0'\n",
    ")\n",
    "\n",
    "\n",
    "launcher = Launcher(\n",
    "    cluster_config=cluster_config,\n",
    "    env_config=env_config,\n",
    "    train_steps=500000000,\n",
    "    opt_learn_rate=1e-4,\n",
    "    rollout_length=30,\n",
    "    test_mode=True,\n",
    "    model_summary_freq=50,\n",
    "    episode_summary_freq=2,\n",
    "    env_render_freq=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "launcher.cluster_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "launcher.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStrategy(BTgymStrategy):\n",
    "    \"\"\"\n",
    "    Example subclass of BT server inner computation startegy.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyStrategy,self).__init__(**kwargs)\n",
    "        \n",
    "        self.order_penalty = 0.5\n",
    "        self.trade_just_closed = False\n",
    "        self.trade_result = None\n",
    "        \n",
    "    def notify_trade(self, trade):\n",
    "        #if trade.justopened:\n",
    "            #print('trade {} just opened'.format(trade.ref))\n",
    "            \n",
    "        if trade.isclosed:\n",
    "            #print('trade {} closed, pnl_comm: {}'.format(trade.ref, trade.pnlcomm))\n",
    "            # Set trade flag and result:\n",
    "            self.trade_just_closed = True\n",
    "            self.trade_result = trade.pnlcomm\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "        \n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Computes featurized RL-ready environment observation state\n",
    "        by applying continious wavelet transform to time-embedded vector\n",
    "        of close-price gradients.\n",
    "        \"\"\"\n",
    "        # Z-normalize raw inputs:\n",
    "        mean = self.p.dataset_stat[1:3].values[0,:-1]\n",
    "        std = self.p.dataset_stat[1:3].values[1,:-1]\n",
    "        X = (self.raw_state - mean) / std\n",
    "        #X = self.raw_state\n",
    "        \n",
    "        # Prepare parameters:\n",
    "        Tau = 2\n",
    "        max_cwt_scale = self.p.state_shape['model_input'].shape[1]\n",
    "        cwt_width = np.linspace(Tau, max_cwt_scale + Tau - 1, max_cwt_scale) # scale of wavelet transdorm [n]\n",
    "    \n",
    "        \n",
    "        # 'gamma'-like signal hyperparameter\n",
    "        # for our signal to be in about [-5,+5] range before passing it to sigmoid;\n",
    "        # tweak it by hand to add/remove \"contrast\":\n",
    "        T = 2.5e+2\n",
    "        \n",
    "        # Get vector of gradients of last [n] prices:\n",
    "        X = np.gradient(X, axis=0) * T\n",
    "        \n",
    "        # Use close price:\n",
    "        channel = 3\n",
    "        # Compute continious wavelet transform using Ricker wavelet, get [n,m,1]-dim. matrix:\n",
    "        self.state['model_input'] = signal.cwt(X[:, channel], signal.ricker, cwt_width).T[:, :, None]\n",
    "        \n",
    "        # Squash values in [0,1]:\n",
    "        self.state['model_input'] = self.sigmoid(self.state['model_input'])\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "\n",
    "    def R(self, val, val_start, R_max, DD_max):\n",
    "        \"\"\"\n",
    "        Piecewise-linear normalized reward:\n",
    "        val > 0         - values scalar or vector;\n",
    "        val_start > 1   - start value, scalar;\n",
    "        0 < R_max < 1   - maximum gain, percent/100,\n",
    "        0 < DD_max < 1  - maximum draw-down, percent/100,\n",
    "                          scalar (minimal acceptable value: = val_start*(1-DD_max) );\n",
    "        returns vector in [-1,+1] range :\n",
    "        \"\"\"\n",
    "\n",
    "        f_neg = np.asarray((val/val_start + DD_max - 1) / DD_max - 1)\n",
    "        f_neg[f_neg > 0] = 0 \n",
    "        f_neg[f_neg < -1] = -0.999\n",
    "        f_pos = np.asarray((val/val_start - 1) / R_max)\n",
    "        f_pos[f_pos < 0] = 0\n",
    "        f_pos[f_pos > 1] = 1 \n",
    "\n",
    "        return (f_neg + f_pos) / 2 +.5  # shift reward to [0,1] range\n",
    "    \n",
    "    def log_utility_R(self, val, val_start, R_max, DD_max, epsilon=0.001):\n",
    "        \"\"\"\n",
    "        Normalized log utility reward function.\n",
    "        Args:\n",
    "            val > 0         - values scalar or vector;\n",
    "            val_start > 1   - start value, scalar;\n",
    "            0 < R_max < 1   - maximum gain, percent/100,\n",
    "            0 < DD_max < 1  - maximum draw-down, percent/100,\n",
    "                              scalar (minimal acceptable value: = val_start*(1-DD_max) );\n",
    "            0 < epsilon <<1 - 'steepness' tuning parameter, scalar;\n",
    "        Returns:\n",
    "            piece-wise log utility in [0,1]\n",
    "        \"\"\"\n",
    "        y = np.asarray((val/val_start + DD_max - 1)/(R_max + DD_max))\n",
    "        y[y <= epsilon] = epsilon\n",
    "        y[y > 1] = 1\n",
    "\n",
    "        return 1 - np.log(y) / np.log(epsilon) \n",
    "    \n",
    "    def power_utility_R(self, val, val_start, R_max, DD_max, power=2):\n",
    "        \"\"\"\n",
    "        Normalized power utility Reward function.\n",
    "        Args:\n",
    "            val > 0         - values scalar or vector;\n",
    "            val_start > 1   - start value, scalar;\n",
    "            0 < R_max < 1   - maximum gain, percent/100,\n",
    "            0 < DD_max < 1  - maximum draw-down, percent/100,\n",
    "                              scalar (minimal acceptable value: = val_start*(1-DD_max) );\n",
    "            1 < power       - 'steepness' tuning parameter, scalar;\n",
    "        Returns:\n",
    "            piece-wise power utility in [0,1]\n",
    "        \"\"\"\n",
    "        y = np.asarray((val/val_start + DD_max - 1)/(R_max + DD_max))\n",
    "        y[y < 0] = 0\n",
    "        y[y > 1] = 1\n",
    "\n",
    "        return y ** power\n",
    "    \n",
    "    def __get_reward(self):\n",
    "        \"\"\"\n",
    "        Defines reward as [0,1]-bounded linear function of current to initial portfolio value ratio.\n",
    "        \"\"\"\n",
    "        r = float(\n",
    "            self.log_utility_R(\n",
    "                val=self.env.broker.get_value(),\n",
    "                val_start=self.env.broker.startingcash,\n",
    "                R_max=self.p.target_call/100,\n",
    "                DD_max=self.p.drawdown_call/100,\n",
    "                epsilon=0.0001\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        r /= 10 # normalize (kind of...)\n",
    "\n",
    "        # Penalty for failed order:\n",
    "        if self.order_failed:\n",
    "            #print('Failed order!')\n",
    "            r -= self.order_penalty\n",
    "            self.order_failed = False\n",
    "        \n",
    "        return r \n",
    "    \n",
    "    def get_reward(self):\n",
    "        \"\"\"\n",
    "        Defines reward as [0,1]-bounded function of last closed trade result.\n",
    "        \"\"\"\n",
    "        r = 0\n",
    "        \n",
    "        # Result\n",
    "        if self.trade_just_closed:\n",
    "            r = self.trade_result\n",
    "            self.trade_just_closed = False\n",
    "            \n",
    "        # Penalty for failed order:\n",
    "        if self.order_failed:\n",
    "            #print('Failed order!')\n",
    "            r -= self.order_penalty\n",
    "            self.order_failed = False\n",
    "            \n",
    "        #print('reward_', r)\n",
    "        \n",
    "        return r / 20\n",
    "            \n",
    "# Set backtesting engine parameters:\n",
    "\n",
    "state_shape = {\n",
    "    'raw_state': spaces.Box(low=-1, high=1, shape=(90, 4)),\n",
    "    'model_input': spaces.Box(low=0, high=1, shape=(90, 20, 1))\n",
    "}\n",
    "\n",
    "MyCerebro = bt.Cerebro()\n",
    "MyCerebro.addstrategy(MyStrategy,\n",
    "                      state_shape=state_shape,\n",
    "                      portfolio_actions=('hold', 'buy', 'sell'),\n",
    "                      drawdown_call=5, # in percent\n",
    "                      target_call=10,\n",
    "                      skip_frame=10,\n",
    "                     )\n",
    "\n",
    "# Set leveraged account:\n",
    "MyCerebro.broker.setcash(2000)\n",
    "MyCerebro.broker.setcommission(commission=0.0001, leverage=10.0)\n",
    "MyCerebro.broker.set_shortcash(False)\n",
    "MyCerebro.addsizer(bt.sizers.SizerFix, stake=10000,)\n",
    "\n",
    "\n",
    "MyCerebro.addanalyzer(bt.analyzers.DrawDown)\n",
    "\n",
    "# Provide data:\n",
    "MyDataset = BTgymDataset(\n",
    "    filename='../data/DAT_ASCII_EURUSD_M1_2016.csv',\n",
    "    #filename='../data/test_sine_1min_period256_delta0002.csv',\n",
    "    start_weekdays=[0, 1, 2, 3, 4],\n",
    "    episode_len_days=0,\n",
    "    episode_len_hours=23,\n",
    "    episode_len_minutes=0,\n",
    "    start_00=True,\n",
    "    time_gap_hours=2,\n",
    ")\n",
    "env_config = dict(\n",
    "    dataset=MyDataset,\n",
    "    engine=MyCerebro,\n",
    "    render_modes=['episode', 'human', 'model_input'],\n",
    "    render_state_as_image=True,\n",
    "    render_ylabel='Z-norm/CWT',\n",
    "    render_size_episode=(12,8),\n",
    "    render_size_human=(8, 3.5),\n",
    "    render_size_state=(10, 5),\n",
    "    render_dpi=75,\n",
    "    port=5000,\n",
    "    data_port=4999,\n",
    "    connect_timeout=60,\n",
    "    verbose=0,\n",
    ")\n",
    "cluster_config = dict(\n",
    "    host='127.0.0.1',\n",
    "    port=12222,\n",
    "    num_workers=8,\n",
    "    num_ps=1,\n",
    "    log_dir='./tmp/a3c_testing',\n",
    ")\n",
    "launcher = Launcher(\n",
    "    cluster_config=cluster_config,\n",
    "    env_class=BTgymEnv,\n",
    "    env_config=env_config,\n",
    "    rollout_length=20,\n",
    "    test_mode=False,\n",
    "    train_steps=1000000000,\n",
    "    model_summary_freq=20,\n",
    "    episode_summary_freq=1,\n",
    "    env_render_freq=20,\n",
    "    verbose=1\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "launcher.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(launcher.kwargs, '\\n\\n')\n",
    "print(launcher.env_config)\n",
    "print(launcher.cluster_config)\n",
    "print(launcher.cluster_spec)\n",
    "for config in launcher.workers_config_list:\n",
    "    print('============')\n",
    "    for k, v in config.items():\n",
    "        print('{}:\\n{}\\n'.format(k, v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func1(max_step):\n",
    "    step = 0\n",
    "    done = False\n",
    "    \n",
    "    def func2(max_step):\n",
    "        nonlocal step\n",
    "        nonlocal done\n",
    "        step +=1\n",
    "        if step == max_step:\n",
    "            step = 0\n",
    "            done = True\n",
    "        return step\n",
    "    \n",
    "    for i in range(20):\n",
    "        done = False\n",
    "        print(func2(max_step), step, done)\n",
    "        \n",
    "\n",
    "\n",
    "func1(7)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = dict()\n",
    "a.update({'b': 2, 'c':4})\n",
    "type(a) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
